import openai
from typing import List, Dict, Any, Optional
import os
import re
from sentence_transformers import SentenceTransformer
from opensearch_client import OpenSearchClient

class RAGService:
    def __init__(self):
        # OpenAI API í‚¤ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key and api_key != "sk-proj-your-actual-api-key-here":
            self.openai_client = openai.OpenAI(api_key=api_key)
        else:
            self.openai_client = None
        
        # SentenceTransformer ì´ˆê¸°í™” (í‚¤ì›Œë“œ ì¶”ì¶œì—ëŠ” OpenSearch ë¶ˆí•„ìš”)
        try:
            self.embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        except Exception as e:
            print(f"Warning: Embedding model initialization failed: {e}")
            self.embedding_model = None
        
        # OpenSearch í´ë¼ì´ì–¸íŠ¸ëŠ” ì„ íƒì ìœ¼ë¡œ ì´ˆê¸°í™”
        try:
            self.opensearch_client = OpenSearchClient()
        except Exception as e:
            print(f"Warning: OpenSearch client initialization failed: {e}")
            self.opensearch_client = None
    
    def _extract_keywords_from_question(self, question: str) -> List[str]:
        """ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        # ë¶ˆìš©ì–´ ëª©ë¡ (í•œêµ­ì–´) - ë” í¬ê´„ì ìœ¼ë¡œ êµ¬ì„±
        stop_words = {
            'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ì™€', 'ê³¼', 'ì˜', 'ë¡œ', 'ìœ¼ë¡œ', 'ë„',
            'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤', 'í•œë‹¤', 'ëœë‹¤', 'í•œ', 'í• ', 'í•´', 'í•˜ëŠ”', 'í•˜ê³ ', 'í•˜ë©°',
            'ë¬´ì—‡', 'ì–´ë–¤', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–¸ì œ', 'ì–´ë””ì„œ', 'ëˆ„ê°€', 'ì–¼ë§ˆë‚˜', 'ì–´ë””',
            'ëŒ€í•´', 'ëŒ€í•œ', 'ê´€ë ¨', 'ê´€í•˜ì—¬', 'ëŒ€í•˜ì—¬', 'ë¬´ì—‡ì¸ì§€', 'ê·¸', 'ì €', 'ì œ',
            'ì•Œë ¤ì£¼ì„¸ìš”', 'ì„¤ëª…í•´ì£¼ì„¸ìš”', 'ê°€ë¥´ì³ì£¼ì„¸ìš”', 'ë§í•´ì£¼ì„¸ìš”', 'ì•Œë ¤ì¤˜', 'ì„¤ëª…í•´ì¤˜',
            'ê·¸ë¦¬ê³ ', 'ë˜í•œ', 'ê·¸ëŸ°ë°', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜', 'ë”°ë¼ì„œ', 'ê·¸ë˜ì„œ',
            'ì‘ì„±í•˜ë‚˜ìš”', 'ì‘ì„±í•´ì£¼ì„¸ìš”', 'í•´ì£¼ì„¸ìš”', 'ì•Œê³ ', 'ì‹¶ìŠµë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'ì¸ê°€ìš”',
            'ìˆë‚˜ìš”', 'ìˆìŠµë‹ˆê¹Œ', 'í•©ë‹ˆê¹Œ', 'ì£¼ì„¸ìš”', 'í•´', 'ì¤˜'
        }
        
        # íŠ¹ìˆ˜ë¬¸ìì™€ ë¬¼ìŒí‘œ ì œê±°
        cleaned_question = re.sub(r'[?!.,;:]', '', question)
        words = cleaned_question.split()
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì¡°ì‚¬ ì œê±°
        keywords = []
        for word in words:
            # ë¶ˆìš©ì–´ê°€ ì•„ë‹ˆê³ , 2ê¸€ì ì´ìƒì´ê³ , í•œê¸€ì´ í¬í•¨ëœ ë‹¨ì–´
            if (word not in stop_words and 
                len(word) >= 2 and 
                re.search(r'[ê°€-í£]', word)):
                # ì¡°ì‚¬ ì œê±° ('ëŠ”', 'ì€', 'ë¥¼', 'ì„', 'ê°€', 'ì´' ë“±)
                cleaned_word = word
                for suffix in ['ëŠ”', 'ì€', 'ë¥¼', 'ì„', 'ê°€', 'ì´', 'ì—ì„œ', 'ì—ê²Œ', 'ìœ¼ë¡œ', 'ë¡œ', 'ì™€', 'ê³¼']:
                    if word.endswith(suffix) and len(word) > len(suffix):
                        cleaned_word = word[:-len(suffix)]
                        break
                
                if len(cleaned_word) >= 2:
                    keywords.append(cleaned_word)
        
        return keywords
    
    def _extract_keywords_from_filename(self, filename: str) -> List[str]:
        """íŒŒì¼ëª…ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        # íŒŒì¼ í™•ì¥ì ì œê±°
        clean_filename = re.sub(r'\.(pdf|hwp|docx?|txt)$', '', filename, flags=re.IGNORECASE)
        
        # ë‚ ì§œ íŒ¨í„´ ì œê±° (2025.08.01 í˜•ì‹)
        clean_filename = re.sub(r'\d{4}\.\d{1,2}\.\d{1,2}', '', clean_filename)
        
        # íŠ¹ìˆ˜ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ë³€ê²½
        clean_filename = re.sub(r'[_\-\(\)\[\]{}]', ' ', clean_filename)
        
        keywords = []
        
        # ë¯¸ë¦¬ ì •ì˜ëœ íŒ¨í„´ ë§¤ì¹­
        patterns = {
            'í•™ì‚¬ìš´ì˜ìœ„ì›íšŒ': ['í•™ì‚¬ìš´ì˜ìœ„ì›íšŒ', 'í•™ì‚¬ìš´ì˜', 'ìš´ì˜ìœ„ì›íšŒ', 'í•™ì‚¬', 'ìœ„ì›íšŒ'],
            'ê·œì •': ['ê·œì •'],
            'ê°œì •': ['ê°œì •'],
            'ì œì •': ['ì œì •'],
            'ì§€ì¹¨': ['ì§€ì¹¨'],
            'ì„¸ì¹™': ['ì„¸ì¹™'],
            'í•™ì‚¬': ['í•™ì‚¬'],
            'ì…í•™': ['ì…í•™'],
            'ì¡¸ì—…': ['ì¡¸ì—…'],
            'ì¥í•™': ['ì¥í•™'],
            'ì—°êµ¬': ['ì—°êµ¬'],
            'ì´ë¬´': ['ì´ë¬´'],
            'êµë¬´': ['êµë¬´'],
            'í•™ìƒ': ['í•™ìƒ'],
            'ëŒ€í•™ì›': ['ëŒ€í•™ì›'],
            'ì „ë¶ëŒ€': ['ì „ë¶ëŒ€í•™êµ', 'ì „ë¶ëŒ€'],
            'ì „ë¶ëŒ€í•™êµ': ['ì „ë¶ëŒ€í•™êµ', 'ì „ë¶ëŒ€'],
        }
        
        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ
        for pattern, related_keywords in patterns.items():
            if pattern in clean_filename:
                keywords.extend(related_keywords)
        
        # ì¶”ê°€ë¡œ 2ê¸€ì ì´ìƒì˜ í•œê¸€ ë‹¨ì–´ë“¤ ì¶”ì¶œ
        words = clean_filename.split()
        for word in words:
            word = word.strip()
            if len(word) >= 2 and re.search(r'[ê°€-í£]', word):
                if word not in keywords:
                    keywords.append(word)
        
        # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ìˆœ ì •ë ¬
        unique_keywords = list(set(keywords))
        unique_keywords.sort(key=len, reverse=True)
        
        return unique_keywords[:8]  # ìƒìœ„ 8ê°œë§Œ ë°˜í™˜
    
    def extract_keywords_with_openai(self, text: str) -> List[str]:
        """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        
        system_prompt = """
ë‹¹ì‹ ì€ í•œêµ­ì˜ ëŒ€í•™ í–‰ì • ë¬¸ì„œì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ë¬¸ì„œ ì œëª©ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
1. ê¸°ê´€ëª… (ì˜ˆ: ì „ë¶ëŒ€í•™êµ, ëŒ€í•™ì› ë“±)
2. ë¶€ì„œ/ì¡°ì§ëª… (ì˜ˆ: í•™ì‚¬ìš´ì˜ìœ„ì›íšŒ, ì´ë¬´ì²˜ ë“±)
3. ë¬¸ì„œ ìœ í˜• (ì˜ˆ: ê·œì •, ì§€ì¹¨, ì„¸ì¹™, ë²•ë ¹ ë“±)
4. ì—…ë¬´ ì˜ì—­ (ì˜ˆ: í•™ì‚¬, ì…í•™, ì¡¸ì—…, ì¥í•™, ì—°êµ¬ ë“±)
5. ìƒíƒœ/ë²„ì „ (ì˜ˆ: ê°œì •, ì œì •, ì‹ ì„¤, íì§€ ë“±)
6. í•µì‹¬ ê°œë…ì–´ (ì˜ˆ: í•™ì , ì‹œí—˜, ìˆ˜ì—…, ë“±ë¡ ë“±)

ê·œì¹™:
- ë³µí•©ì–´ë¥¼ ë‹¨ê³„ë³„ë¡œ ë¶„í•´í•´ì„œ ì¶”ì¶œ (ì˜ˆ: "í•™ì‚¬ìš´ì˜ìœ„ì›íšŒ" â†’ ["í•™ì‚¬ìš´ì˜ìœ„ì›íšŒ", "í•™ì‚¬ìš´ì˜", "ìš´ì˜ìœ„ì›íšŒ", "í•™ì‚¬", "ìœ„ì›íšŒ"])
- ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë§Œ ì¶”ì¶œ (ì¡°ì‚¬, ì–´ë¯¸ ë“±ì€ ì œì™¸)
- 2ê¸€ì ì´ìƒì˜ ë‹¨ì–´ë§Œ ì¶”ì¶œ
- ì¤‘ë³µ ì œê±°
- ê¸´ í‚¤ì›Œë“œë¶€í„° ì •ë ¬

ì‘ë‹µì€ ë°˜ë“œì‹œ JSON ë°°ì—´ í˜•íƒœë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”.
ì˜ˆì‹œ: ["í•™ì‚¬ìš´ì˜ìœ„ì›íšŒ", "í•™ì‚¬ìš´ì˜", "ìš´ì˜ìœ„ì›íšŒ", "í•™ì‚¬", "ìœ„ì›íšŒ", "ê·œì •", "ê°œì •"]
"""
        
        user_prompt = f"ë‹¤ìŒ ë¬¸ì„œ ì œëª©ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:\n\n{text}"
        
        try:
            # Check if OpenAI API key is configured
            if not os.getenv("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY") == "sk-proj-your-actual-api-key-here":
                # Fallback to filename extraction
                return self._extract_keywords_from_filename(text)
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            
            result = response.choices[0].message.content.strip()
            
            # Parse JSON response
            import json
            try:
                keywords = json.loads(result)
                if isinstance(keywords, list):
                    # Filter and clean keywords
                    cleaned_keywords = [
                        keyword.strip() 
                        for keyword in keywords 
                        if isinstance(keyword, str) and len(keyword.strip()) >= 2
                    ]
                    return cleaned_keywords[:10]  # Limit to top 10 keywords
                else:
                    # If not a list, fallback to filename extraction
                    return self._extract_keywords_from_filename(text)
            except json.JSONDecodeError:
                # If JSON parsing fails, fallback to filename extraction
                return self._extract_keywords_from_filename(text)
                
        except Exception as e:
            print(f"OpenAI keyword extraction failed: {e}")
            # Fallback to filename extraction
            return self._extract_keywords_from_filename(text)
    
    def _highlight_keywords(self, text: str, keywords: List[str]) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ í•˜ì´ë¼ì´íŠ¸í•©ë‹ˆë‹¤. ë¶€ë¶„ ë§¤ì¹˜ì™€ ìœ ì‚¬ ë‹¨ì–´ë„ í¬í•¨."""
        if not keywords:
            return text
        
        highlighted_text = text
        
        for keyword in keywords:
            # 1. ì •í™•í•œ ë§¤ì¹˜
            if keyword in highlighted_text:
                highlighted_text = re.sub(
                    f'({re.escape(keyword)})', 
                    r'<mark>\1</mark>', 
                    highlighted_text, 
                    flags=re.IGNORECASE
                )
            else:
                # 2. ë¶€ë¶„ ë§¤ì¹˜ (2ê¸€ì ì´ìƒì¼ ë•Œ)
                if len(keyword) >= 3:
                    for i in range(len(keyword)-1):
                        partial = keyword[i:i+2]
                        if partial in highlighted_text and len(partial) >= 2:
                            highlighted_text = re.sub(
                                f'({re.escape(partial)})', 
                                r'<mark>\1</mark>', 
                                highlighted_text, 
                                flags=re.IGNORECASE
                            )
                            break
                
                # 3. ê´€ë ¨ ë‹¨ì–´ ë§¤ì¹˜
                related_words = {
                    'ì¬í•™ê¸°ê°„': ['ì¬í•™', 'í•™ê¸°', 'ê¸°ê°„', 'ìˆ˜í•™'],
                    'ì—°ì¥': ['ì—°ì¥', 'ì—°ê¸°', 'ê¸°ê°„'],
                    'ì‹ ì²­ì„œ': ['ì‹ ì²­', 'ì„œë¥˜', 'ì‹ ì²­ì„œ', 'í—ˆê°€']
                }
                
                if keyword in related_words:
                    for related in related_words[keyword]:
                        if related in highlighted_text:
                            highlighted_text = re.sub(
                                f'({re.escape(related)})', 
                                r'<mark>\1</mark>', 
                                highlighted_text, 
                                flags=re.IGNORECASE
                            )
        
        # ì¤‘ë³µ ë§ˆí¬ì—… ì œê±°
        highlighted_text = re.sub(r'<mark>(<mark>[^<]*</mark>)</mark>', r'\1', highlighted_text)
        highlighted_text = re.sub(r'<mark><mark>([^<]*)</mark></mark>', r'<mark>\1</mark>', highlighted_text)
        
        return highlighted_text
    
    def get_individual_answers(self, question: str, assistant_ids: List[str], summary_mode: bool = False) -> Dict[str, Any]:
        """ê° assistantë³„ë¡œ ê°œë³„ ì‘ë‹µì„ ìƒì„±í•˜ì—¬ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤."""
        individual_responses = []
        all_keywords = set()
        
        # ë¹„êµ ì§ˆë¬¸ì¸ ê²½ìš° ê°œë³„ ì–´ì‹œìŠ¤í„´íŠ¸ìš© ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜
        comparison_keywords = ["ë¹„êµ", "ì°¨ì´", "ë‹¤ë¥¸ì ", "êµ¬ë³„", "í‘œ", "ë¶„ì„", "ëŒ€ì¡°", "vs", "versus", "ë¹„êµë¶„ì„", "í•­ëª©ë³„ë¡œ", "í•­ëª©ë³„", "í•­ëª©ìœ¼ë¡œ", "êµ¬ë¶„í•˜ì—¬", "ë‚˜ëˆ„ì–´"]
        is_comparison_question = any(keyword in question for keyword in comparison_keywords)
        
        for assistant_id in assistant_ids:
            try:
                # ë¹„êµ ì§ˆë¬¸ì¸ ê²½ìš° ê°œë³„ ê²€ìƒ‰ìš© ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜
                if is_comparison_question:
                    # "íœ´í•™ ê·œì •ì„ í•­ëª©ë³„ë¡œ ë¹„êµí•´ì¤˜" -> "íœ´í•™ ê·œì •ì— ëŒ€í•´ ì•Œë ¤ì¤˜"
                    individual_question = self._convert_to_individual_question(question)
                else:
                    individual_question = question
                    
                response = self.get_answer(individual_question, assistant_id, summary_mode)
                individual_responses.append({
                    'assistant_id': assistant_id,
                    'assistant_name': assistant_id,  # TODO: Get actual assistant name from DB
                    'answer': response['answer'],
                    'sources': response['sources'],
                    'confidence': response['confidence'],
                    'keywords': response['keywords']
                })
                # Collect all keywords
                if 'keywords' in response:
                    all_keywords.update(response['keywords'])
            except Exception as e:
                individual_responses.append({
                    'assistant_id': assistant_id,
                    'assistant_name': assistant_id,
                    'answer': f"ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì–´ì‹œìŠ¤í„´íŠ¸ì—ì„œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                    'sources': [],
                    'confidence': 0.0,
                    'keywords': [],
                    'error': str(e)
                })
        
        # ë¹„êµ í‚¤ì›Œë“œ í™•ì¸ ë° ìë™ ë¹„êµí‘œ ìƒì„±
        comparison_keywords = ["ë¹„êµ", "ì°¨ì´", "ë‹¤ë¥¸ì ", "êµ¬ë³„", "í‘œ", "ë¶„ì„", "ëŒ€ì¡°", "vs", "versus", "ë¹„êµë¶„ì„", "í•­ëª©ë³„ë¡œ", "í•­ëª©ë³„", "í•­ëª©ìœ¼ë¡œ", "êµ¬ë¶„í•˜ì—¬", "ë‚˜ëˆ„ì–´"]
        has_comparison = any(keyword in question for keyword in comparison_keywords)
        
        result = {
            'response_type': 'individual',
            'individual_responses': individual_responses,
            'total_assistants': len(assistant_ids),
            'keywords': list(all_keywords)
        }
        
        # ë¹„êµ í‚¤ì›Œë“œê°€ ìˆê³  2ê°œ ì´ìƒì˜ ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ìˆìœ¼ë©´ ë¹„êµí‘œ ìƒì„±
        if has_comparison and len(assistant_ids) >= 2 and len(individual_responses) >= 2:
            try:
                comparison_table = self._generate_comparison_table(question, individual_responses)
                if comparison_table:
                    result['comparison_table'] = comparison_table
            except Exception as e:
                print(f"ë¹„êµí‘œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return result
    
    def _convert_to_individual_question(self, question: str) -> str:
        """ë¹„êµ ì§ˆë¬¸ì„ ê°œë³„ ê²€ìƒ‰ìš© ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        # ë¹„êµ ê´€ë ¨ í‚¤ì›Œë“œ ì œê±°í•˜ê³  í•µì‹¬ ì£¼ì œë§Œ ì¶”ì¶œ
        comparison_patterns = [
            r'ì„?\s*í•­ëª©ë³„ë¡œ\s*ë¹„êµí•´?[ë‹¬ë¼|ì¤˜]?',
            r'ë¥¼?\s*í•­ëª©ë³„ë¡œ\s*ë¹„êµí•´?[ë‹¬ë¼|ì¤˜]?',
            r'ì„?\s*ë¹„êµí•´?[ë‹¬ë¼|ì¤˜]?',
            r'ë¥¼?\s*ë¹„êµí•´?[ë‹¬ë¼|ì¤˜]?',
            r'í•­ëª©ë³„ë¡œ\s*',
            r'ë¹„êµí•´?[ë‹¬ë¼|ì¤˜]?',
            r'ì°¨ì´ì ?ì„?\s*',
            r'ë‹¤ë¥¸ì ?ì„?\s*',
            r'êµ¬ë³„í•´?[ë‹¬ë¼|ì¤˜]?',
            r'ë¶„ì„í•´?[ë‹¬ë¼|ì¤˜]?',
            r'ëŒ€ì¡°í•´?[ë‹¬ë¼|ì¤˜]?'
        ]
        
        import re
        converted_question = question
        
        # íŒ¨í„´ë³„ë¡œ ì œê±°
        for pattern in comparison_patterns:
            converted_question = re.sub(pattern, '', converted_question)
        
        # ê³µë°± ì •ë¦¬
        converted_question = re.sub(r'\s+', ' ', converted_question).strip()
        
        # ê¸°ë³¸ ì§ˆë¬¸ í˜•íƒœë¡œ ë³€í™˜
        if not converted_question.endswith(('ì— ëŒ€í•´', 'ì— ëŒ€í•´ì„œ', 'ì— ê´€í•´', 'ì— ê´€í•´ì„œ', 'ì€?', 'ëŠ”?', 'ì„?', 'ë¥¼?')):
            if converted_question:
                converted_question += 'ì— ëŒ€í•´ ì•Œë ¤ì¤˜'
            else:
                converted_question = question  # ë³€í™˜ ì‹¤íŒ¨ì‹œ ì›ë³¸ ì‚¬ìš©
        else:
            converted_question += ' ì•Œë ¤ì¤˜'
            
        return converted_question
    
    def _expand_short_query(self, question: str) -> str:
        """ì§§ì€ ì§ˆì˜ë¥¼ í™•ì¥í•˜ì—¬ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ"""
        # ì¼ë°˜ì ì¸ í•™ì‚¬ ê´€ë ¨ ì§§ì€ ì§ˆì˜ í™•ì¥ íŒ¨í„´
        expansion_patterns = {
            # í•™ì‚¬ ê´€ë ¨
            'íœ´í•™': 'íœ´í•™ ì‹ ì²­ ë°©ë²• ì ˆì°¨ ì¡°ê±´',
            'ë³µí•™': 'ë³µí•™ ì‹ ì²­ ë°©ë²• ì ˆì°¨ ì¡°ê±´',
            'ë“±ë¡': 'ë“±ë¡ê¸ˆ ë‚©ë¶€ ë°©ë²• ê¸°ê°„',
            'ìˆ˜ê°•': 'ìˆ˜ê°•ì‹ ì²­ ë°©ë²• ì ˆì°¨ ê¸°ê°„',
            'ì¡¸ì—…': 'ì¡¸ì—… ìš”ê±´ ì¡°ê±´ ì ˆì°¨',
            'í•™ì ': 'í•™ì  ì´ìˆ˜ ìš”ê±´ ì¡°ê±´',
            'ì„±ì ': 'ì„±ì  í‰ê°€ ê¸°ì¤€ ë°©ë²•',
            'ì¥í•™ê¸ˆ': 'ì¥í•™ê¸ˆ ì‹ ì²­ ë°©ë²• ì¡°ê±´',
            'ì „ê³¼': 'ì „ê³¼ ì‹ ì²­ ë°©ë²• ì¡°ê±´',
            'ë¶€ì „ê³µ': 'ë¶€ì „ê³µ ì‹ ì²­ ë°©ë²• ì¡°ê±´',
            'ë³µìˆ˜ì „ê³µ': 'ë³µìˆ˜ì „ê³µ ì‹ ì²­ ë°©ë²• ì¡°ê±´',
            'í•™ì‚¬ê²½ê³ ': 'í•™ì‚¬ê²½ê³  ê¸°ì¤€ ì¡°ì¹˜',
            'ê³„ì ˆí•™ê¸°': 'ê³„ì ˆí•™ê¸° ì‹ ì²­ ë°©ë²•',
            'êµí™˜í•™ìƒ': 'êµí™˜í•™ìƒ ì‹ ì²­ ë°©ë²•',
            
            # í–‰ì • ê´€ë ¨
            'ë“±ë¡ì¦ëª…ì„œ': 'ë“±ë¡ì¦ëª…ì„œ ë°œê¸‰ ë°©ë²•',
            'ì¬í•™ì¦ëª…ì„œ': 'ì¬í•™ì¦ëª…ì„œ ë°œê¸‰ ë°©ë²•',
            'ì„±ì ì¦ëª…ì„œ': 'ì„±ì ì¦ëª…ì„œ ë°œê¸‰ ë°©ë²•',
            'ì¡¸ì—…ì¦ëª…ì„œ': 'ì¡¸ì—…ì¦ëª…ì„œ ë°œê¸‰ ë°©ë²•',
            
            # ê¸°íƒ€
            'ê¸°ìˆ™ì‚¬': 'ê¸°ìˆ™ì‚¬ ì‹ ì²­ ë°©ë²• ì¡°ê±´',
            'ë„ì„œê´€': 'ë„ì„œê´€ ì´ìš© ë°©ë²• ì‹œê°„'
        }
        
        # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš° í™•ì¥
        for keyword, expansion in expansion_patterns.items():
            if keyword in question:
                return f"{question} {expansion}"
        
        # íŒ¨í„´ì— ì—†ëŠ” ê²½ìš° ì¼ë°˜ì ì¸ í™•ì¥
        if '?' in question or 'ë¬´ì—‡' in question or 'ì–´ë–»ê²Œ' in question:
            return f"{question} ë°©ë²• ì ˆì°¨ ì¡°ê±´"
        else:
            return f"{question}ì— ëŒ€í•´ ìì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš”"
    
    def _generate_comparison_table(self, question: str, individual_responses: List[Dict]) -> str:
        """ê°œë³„ ì‘ë‹µë“¤ì„ ë¶„ì„í•˜ì—¬ ë¹„êµí‘œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # ì–´ì‹œìŠ¤í„´íŠ¸ë³„ ë‹µë³€ ë‚´ìš© ì •ë¦¬ (ê¸¸ì´ ì œí•œ)
            assistant_data = {}
            for response in individual_responses:
                assistant_id = response['assistant_id']
                answer = response['answer']
                # ë‹µë³€ì„ 200ìë¡œ ì œí•œí•´ì„œ í† í° ì ˆì•½
                truncated_answer = answer[:200] + "..." if len(answer) > 200 else answer
                assistant_data[assistant_id] = truncated_answer
            
            # OpenAIë¥¼ í†µí•´ ë¹„êµí‘œ ìƒì„±
            if not self.openai_client:
                return None
                
            # ë¹„êµí‘œ ìƒì„±ì„ ìœ„í•œ ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ (ì»¬ëŸ¼ ì •ë ¬ ê°œì„ )
            assistant_names = list(assistant_data.keys())
            comparison_prompt = f"""ì§ˆë¬¸: {question}

ê° ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ë‹µë³€:
{chr(10).join([f"ì–´ì‹œìŠ¤í„´íŠ¸ {aid}: {answer}" for aid, answer in assistant_data.items()])}

ìœ„ ë‹µë³€ë“¤ì„ ë¶„ì„í•˜ì—¬ ë¹„êµí‘œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ì§€ì¹¨ì„ ì •í™•íˆ ë”°ë¼ì£¼ì„¸ìš”:

1. ê° ë‹µë³€ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì ê·¹ì ìœ¼ë¡œ ì°¾ì•„ ì¶”ì¶œí•˜ì„¸ìš”
2. "êµ¬ì²´ì ì¸ ë‚´ìš©ì´ ì—†ë‹¤"ê±°ë‚˜ "ë‚˜ì™€ìˆì§€ ì•Šë‹¤"ëŠ” ë‹µë³€ì´ ìˆì–´ë„, ìœ ì‚¬í•œ ë‚´ìš©ì´ë‚˜ ê´€ë ¨ ê·œì •ì´ ìˆë‹¤ë©´ í¬í•¨í•˜ì„¸ìš”
3. HTML í‘œ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”:
   - ì²« ë²ˆì§¸ ì—´: ë¹„êµí•­ëª© (ì˜ˆ: ì‹ ì²­ ì ˆì°¨, ìŠ¹ì¸ ì¡°ê±´, ê¸°ê°„ ì œí•œ ë“±)
   - ì´í›„ ì—´ë“¤: ê° ì–´ì‹œìŠ¤í„´íŠ¸ ({', '.join(assistant_names)})
4. ê° ì…€ì€ ê°„ê²°í•˜ê²Œ 40ì ì´ë‚´ë¡œ ìš”ì•½í•˜ì„¸ìš”
5. ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ "ëª…ì‹œë˜ì§€ ì•ŠìŒ"ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”

ì •í™•í•œ HTML í…Œì´ë¸” í˜•ì‹:
<table style="border-collapse: collapse; width: 100%; border: 1px solid #ddd;">
<thead>
<tr style="background-color: #f8f9fa;">
<th style="border: 1px solid #ddd; padding: 12px; text-align: left; font-weight: bold;">ë¹„êµí•­ëª©</th>
{chr(10).join([f'<th style="border: 1px solid #ddd; padding: 12px; text-align: left; font-weight: bold;">{aid}</th>' for aid in assistant_names])}
</tr>
</thead>
<tbody>
ê° ë¹„êµ í•­ëª©ë³„ë¡œ <tr> í–‰ì„ ì¶”ê°€í•˜ì„¸ìš”
</tbody>
</table>

ë¹„êµí‘œë¥¼ ìœ„ í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ê°„ê²°í•œ ë¹„êµí‘œë¥¼ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": comparison_prompt}
                ],
                temperature=0.2,
                max_tokens=800
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"ë¹„êµí‘œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None
    
    def get_answer(self, question: str, assistant_id: Optional[str] = None, summary_mode: bool = False) -> Dict[str, Any]:
        # UTF-8 ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
        try:
            if isinstance(question, bytes):
                question = question.decode('utf-8')
            # ì¸ì½”ë”©ì´ ê¹¨ì§„ ê²½ìš° ë³µêµ¬ ì‹œë„
            elif 'Ã¬' in question or 'Ã«' in question:
                # ì¸ì½”ë”©ì´ ì˜ëª»ëœ ê²½ìš° ì¬ì¸ì½”ë”©
                question = question.encode('latin1').decode('utf-8')
        except:
            pass  # ì¸ì½”ë”© ë³µêµ¬ ì‹¤íŒ¨ì‹œ ì›ë³¸ ì‚¬ìš©
        
        # 0. ì§§ì€ ì§ˆì˜ í™•ì¥ (3ë‹¨ì–´ ì´í•˜ì¸ ê²½ìš°)
        if len(question.split()) <= 3:
            question = self._expand_short_query(question)
        
        # 1. ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords_from_question(question)
        
        # 2. ë¹„êµ ëª¨ë“œ ë° ì–´ì‹œìŠ¤í„´íŠ¸ ì¡°ê±´ í™•ì¸ (ë³€ìˆ˜ ì´ˆê¸°í™”)
        comparison_keywords = ["ë¹„êµ", "ì°¨ì´", "ë‹¤ë¥¸ì ", "êµ¬ë³„", "í‘œ", "ë¶„ì„", "ëŒ€ì¡°", "vs", "versus", "ë¹„êµë¶„ì„"]
        has_comparison = any(keyword in question for keyword in comparison_keywords)
        multiple_assistants = isinstance(assistant_id, list) and len(assistant_id) > 1
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ ì„¤ì • (ë¹„êµ ëª¨ë“œì—ì„œëŠ” í† í° ì ˆì•½)
        content_limit = 300 if (summary_mode and has_comparison and multiple_assistants) else 1500
        
        # 3. ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        question_embedding = self.embedding_model.encode(question).tolist()
        
        # 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ë¬¸ì„œ ì²­í¬ ê²€ìƒ‰ (í‚¤ì›Œë“œ + ë²¡í„° ê²€ìƒ‰ with RRF)
        # top_k=5ë¡œ ì¡°ì •í•˜ì—¬ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë§Œ ì„ ë³„
        # ë¹„êµ ëª¨ë“œì—ì„œëŠ” ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œì„ ê³ ë ¤í•˜ì—¬ ë” ì ì€ ì²­í¬ ì‚¬ìš©
        if summary_mode and has_comparison and multiple_assistants:
            search_size = 6  # ë¹„êµ ëª¨ë“œ (8->6)
            assistant_search_size = 3  # ê° ì–´ì‹œìŠ¤í„´íŠ¸ë‹¹ (4->3)
        else:
            search_size = 5 if summary_mode else 5  # í†µì¼ëœ í¬ê¸°ë¡œ ì¡°ì • (20->5, 10->5)
            assistant_search_size = 5 if summary_mode else 3  # ê° ì–´ì‹œìŠ¤í„´íŠ¸ë‹¹ (10->5, 6->3)
        
        if isinstance(assistant_id, list):
            # ì—¬ëŸ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì—ì„œ ê²€ìƒ‰
            all_chunks = []
            for aid in assistant_id:
                # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš©
                chunks = self.opensearch_client.hybrid_search(
                    question, 
                    question_embedding,
                    assistant_id=aid,
                    size=assistant_search_size  # ê° ì–´ì‹œìŠ¤í„´íŠ¸ë‹¹ ê°œìˆ˜
                )
                all_chunks.extend(chunks)
            # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ì„ íƒ
            similar_chunks = sorted(all_chunks, key=lambda x: x['_score'], reverse=True)[:search_size]
        else:
            # ë‹¨ì¼ ì–´ì‹œìŠ¤í„´íŠ¸ ë˜ëŠ” ì „ì²´ ê²€ìƒ‰ - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš©
            similar_chunks = self.opensearch_client.hybrid_search(
                question,
                question_embedding, 
                assistant_id=assistant_id,
                size=search_size
            )
        
        if not similar_chunks:
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "sources": [],
                "confidence": 0.0,
                "keywords": keywords
            }
        
        # 4. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ë° í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŠ¸
        context_parts = []
        sources = []
        
        for hit in similar_chunks:
            source = hit['_source']
            score = hit['_score']
            
            # ì›ë³¸ ë‚´ìš©ê³¼ í•˜ì´ë¼ì´íŠ¸ëœ ë‚´ìš© ëª¨ë‘ ì €ì¥
            original_content = source['content']
            highlighted_content = self._highlight_keywords(original_content, keywords)
            
            context_parts.append(f"ë¬¸ì„œ: {source['document_title']}, í˜ì´ì§€: {source['page_number']}\në‚´ìš©: {original_content}")
            
            sources.append({
                "document_title": source['document_title'],
                "page_number": source['page_number'],
                "chunk_index": source['chunk_index'],
                "content": original_content,
                "highlighted_content": highlighted_content,
                "tags": source['tags'],
                "organization": source['organization'],
                "document_type": source['document_type'],
                "relevance_score": score
            })
        
        # 4. OpenAI APIë¡œ ë‹µë³€ ìƒì„±
        # Summary modeì™€ ë¹„êµ ì§ˆë¬¸ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì„ íƒ
        
        if summary_mode and (has_comparison or multiple_assistants):
            print(f"DEBUG: ë¹„êµ ëª¨ë“œ ì§„ì… - summary_mode: {summary_mode}, has_comparison: {has_comparison}, multiple_assistants: {multiple_assistants}")
            # ì–´ì‹œìŠ¤í„´íŠ¸ë³„ ë¬¸ì„œ ì •ë¦¬ - similar_chunksì—ì„œ ì§ì ‘ ê°€ì ¸ì˜´
            assistant_docs = {}
            for i, chunk in enumerate(similar_chunks):
                print(f"DEBUG: ì²­í¬ {i} êµ¬ì¡°: {list(chunk.keys())}")
                print(f"DEBUG: _source í‚¤ë“¤: {list(chunk['_source'].keys()) if '_source' in chunk else 'No _source'}")
                assistant = chunk['_source'].get('assistant_id', 'Unknown')
                print(f"DEBUG: ì²­í¬ {i} - assistant: {assistant}")
                if assistant not in assistant_docs:
                    assistant_docs[assistant] = []
                # sourcesì—ì„œ í•´ë‹¹í•˜ëŠ” source ì°¾ê¸°
                if i < len(sources):
                    assistant_docs[assistant].append(sources[i])
            
            print(f"DEBUG: assistant_docs keys: {list(assistant_docs.keys())}")
            
            assistant_list = list(assistant_docs.keys())
            context_by_assistant = ""
            
            for assistant, docs in assistant_docs.items():
                context_by_assistant += f"\n\n=== {assistant} ê´€ë ¨ ë¬¸ì„œ ===\n"
                for doc in docs:
                    content = doc.get('content', '').strip()
                    if content:  # ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ ì¶”ê°€
                        context_by_assistant += f"[{doc.get('document_title', 'Unknown')} - í˜ì´ì§€ {doc.get('page_number', 'Unknown')}]\n"
                        # ë¹„êµ ëª¨ë“œì—ì„œëŠ” ê° ë¬¸ì„œ ë‚´ìš©ì„ ë” ì§§ê²Œ ì œí•œ
                        truncated_content = content[:content_limit]
                        if len(content) > content_limit:
                            truncated_content += "..."
                        context_by_assistant += f"{truncated_content}\n\n"
            
            # í‘œ í—¤ë” ìƒì„±
            table_headers = '<th style="border: 1px solid #ddd; padding: 8px;">ë¹„êµí•­ëª©</th>'
            for assistant in assistant_list:
                table_headers += f'<th style="border: 1px solid #ddd; padding: 8px;">{assistant}</th>'
            
            # ì˜ˆì‹œ í–‰ ìƒì„±
            example_row = '<td style="border: 1px solid #ddd; padding: 8px;">ë¹„êµê¸°ì¤€</td>'
            for _ in assistant_list:
                example_row += '<td style="border: 1px solid #ddd; padding: 8px;">í•´ë‹¹ ë‚´ìš©</td>'
            
            system_prompt = f"""
ë‹¹ì‹ ì€ ê·œì •ê³¼ ì§€ì¹¨ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì§€ì¹¨:
1. ì œê³µëœ ì–´ì‹œìŠ¤í„´íŠ¸ë³„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë¹„êµ ë¶„ì„í•˜ì„¸ìš”.
2. ê° ì–´ì‹œìŠ¤í„´íŠ¸ë³„ë¡œ ì°¨ì´ì ì„ ë°˜ë“œì‹œ HTML í‘œ í˜•íƒœë¡œ ì •ë¦¬í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.
3. í‘œëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ ì‘ì„±í•˜ì„¸ìš” (ì–´ì‹œìŠ¤í„´íŠ¸ IDê°€ ì»¬ëŸ¼, ë¹„êµí•­ëª©ì´ í–‰):
   <table style="border-collapse: collapse; width: 100%;">
   <thead><tr style="background-color: #f0f0f0;">{table_headers}</tr></thead>
   <tbody>
   <tr>{example_row}</tr>
   </tbody>
   </table>
4. í‘œì˜ ê° ì…€ì—ëŠ” í•´ë‹¹ ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ê´€ë ¨ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ì¬í•˜ì„¸ìš”.
5. í‘œ ì‘ì„± ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ì¤€ìˆ˜í•˜ì„¸ìš”:
   - ì²« ë²ˆì§¸ ì»¬ëŸ¼ì€ ë¹„êµí•­ëª©(ê¸°ì¤€)ì´ê³ , ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ì€ ê° ì–´ì‹œìŠ¤í„´íŠ¸ IDì…ë‹ˆë‹¤.
   - ê° í–‰ì€ í•˜ë‚˜ì˜ ë¹„êµê¸°ì¤€ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
   - ë™ì¼í•œ í•­ëª©ì— ëŒ€í•œ ê° ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ë‚´ìš©ì„ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•˜ì„¸ìš”.
6. í‘œ ì™¸ì—ë„ í•µì‹¬ ì°¨ì´ì ê³¼ ê³µí†µì ì„ ìš”ì•½í•´ì„œ ì„¤ëª…í•˜ì„¸ìš”.
7. ë‹µë³€ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì„œì™€ í˜ì´ì§€ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
8. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.

ì–´ì‹œìŠ¤í„´íŠ¸ë³„ ë¬¸ì„œ ë‚´ìš©:
{context_by_assistant}
"""
        elif summary_mode:
            system_prompt = """
ë‹¹ì‹ ì€ ê·œì •ê³¼ ì§€ì¹¨ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì§€ì¹¨:
1. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
2. ë‚´ìš©ì„ ì²´ê³„ì ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
3. ì¤‘ìš”í•œ í¬ì¸íŠ¸ë“¤ì„ ì •ë¦¬í•´ì„œ ì œì‹œí•˜ì„¸ìš”.
4. ë‹µë³€ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì„œì™€ í˜ì´ì§€ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
5. ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
6. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
"""
        else:
            system_prompt = """
ë‹¹ì‹ ì€ ê·œì •ê³¼ ì§€ì¹¨ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì§€ì¹¨:
1. ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
2. ë‹µë³€í•  ìˆ˜ ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´ ì†”ì§íˆ ëª¨ë¥¸ë‹¤ê³  í•˜ì„¸ìš”.
3. ë‹µë³€ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì„œì™€ í˜ì´ì§€ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
4. ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
5. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
"""
        
        # ëª¨ë“  ëª¨ë“œì—ì„œ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = ""
        
        for source in sources:
            source_data = source.get('_source', source)
            content = source_data.get('content', '').strip()
            if content:  # ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
                context += f"[{source_data.get('document_title', 'Unknown')} - í˜ì´ì§€ {source_data.get('page_number', 'Unknown')}]\n"
                # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ ì ìš©
                truncated_content = content[:content_limit]
                if len(content) > content_limit:
                    truncated_content += "..."
                context += f"{truncated_content}\n\n"
        
        user_prompt = f"""
ì§ˆë¬¸: {question}

ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©:
{context}

ìœ„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ë‹µë³€ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì„œëª…ê³¼ í˜ì´ì§€ë¥¼ ë°˜ë“œì‹œ ëª…ì‹œí•´ì£¼ì„¸ìš”.
"""
        
        try:
            # Check if OpenAI API key is properly configured
            if not self.openai_client:
                # Provide a basic answer using retrieved documents without OpenAI
                answer = f"ê´€ë ¨ ë¬¸ì„œ {len(sources)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n\n"
                for i, source in enumerate(sources[:3], 1):
                    source_data = source.get('_source', source)
                    content = source_data.get('content', '').strip()
                    if content:  # ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ í‘œì‹œ
                        answer += f"{i}. {source_data.get('document_title', 'Unknown')} (í˜ì´ì§€ {source_data.get('page_number', 'Unknown')})\n"
                        answer += f"   ë‚´ìš©: {content[:200]}...\n\n"
                
                
                return {
                    "response_type": "integrated",
                    "answer": answer,
                    "sources": sources,
                    "confidence": min(similar_chunks[0]['_score'] if similar_chunks else 0, 1.0),
                    "total_sources": len(sources),
                    "keywords": keywords
                }
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                max_tokens=1500
            )
            
            answer = response.choices[0].message.content
            
            return {
                "response_type": "integrated",
                "answer": answer,
                "sources": sources,
                "confidence": min(similar_chunks[0]['_score'] if similar_chunks else 0, 1.0),
                "total_sources": len(sources),
                "keywords": keywords
            }
            
        except Exception as e:
            # Log the actual error for debugging
            print(f"OpenAI API Error Details: {str(e)}")
            print(f"Error type: {type(e).__name__}")
            # Provide helpful fallback when OpenAI is unavailable
            answer = f"ğŸ’¡ **ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ ì •ë³´**\n\n"
            for i, source in enumerate(sources[:3], 1):
                answer += f"**{i}. {source['document_title']}** (í˜ì´ì§€ {source['page_number']})\n"
                content_preview = source['content'][:300] + "..." if len(source['content']) > 300 else source['content']
                answer += f"{content_preview}\n\n"
            
            if len(sources) > 3:
                answer += f"ğŸ“„ ì´ {len(sources)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n\n"
            
            return {
                "response_type": "integrated",
                "answer": answer,
                "sources": sources,
                "confidence": 0.5,
                "keywords": keywords,
                "error": str(e)
            }